# LLM-Agents-TFM
LLM project to generate agents able to do exams and correct them

#  Proyecto LLM con Ollama y Python 3.8

Este proyecto utiliza modelos de lenguaje (LLM) a trav茅s de [Ollama](https://ollama.com/) en combinaci贸n con scripts de Python para consultas, pruebas RAG y generaci贸n de embeddings, usando `llama-index` y `requests`.

Est谩 dise帽ado para ser ejecutado de forma sencilla mediante Docker Compose, incluyendo soporte para GPU si est谩 disponible.

# Levantar Docker-Compose

El archivo docker-compose.yml puede levantarse lanzando el siguiente comando desde bash en la ruta del proyecto:

docker compose up -d

Dicho .yml aplica la aceleraci贸n por GPU mediante CUDA. En caso de no poder utilizarla se requiere eliminar la siguiente secci贸n del archivo:

deploy:
  resources:
    reservations:
      devices:
        - capabilities: [gpu]

Para apagar el servicio se har铆a mediante el siguiente comando:

docker compose down

# build_index.py y simpsons_script.py

El archivo simpsons_script.py sirve para generar un dataset al mismo nivel que el proyecto en una carpeta llamada simpsons_data.

El script de build_index.py toma la ruta generada del dataset anterior y genera la base de datos e indexaci贸n en ChromaDB.

El efecto de ambos scripts es persistente, se guarda memoria en el docker-compose.yml para tal fin, as铆 la aplicaci贸n solo ha de realizarse una vez en el contenedor.
