# LLM-Agents-TFM
LLM project to generate agents able to do exams and correct them

# 游 Proyecto LLM con Ollama y Python 3.8

Este proyecto utiliza modelos de lenguaje (LLM) a trav칠s de [Ollama](https://ollama.com/) en combinaci칩n con scripts de Python para consultas, pruebas RAG y generaci칩n de embeddings, usando `llama-index` y `requests`.

Est치 dise침ado para ser ejecutado de forma sencilla mediante Docker Compose, incluyendo soporte para GPU si est치 disponible.

# Levantar Docker-Compose

El archivo docker-compose.yml puede levantarse lanzando el siguiente comando desde bash en la ruta del proyecto:

docker compose up -d

Dicho .yml aplica la aceleraci칩n por GPU mediante CUDA. En caso de no poder utilizarla se requiere eliminar la siguiente secci칩n del archivo:

deploy:
  resources:
    reservations:
      devices:
        - capabilities: [gpu]

Para apagar el servicio se har칤a mediante el siguiente comando:

docker compose down
